# HDF5-UDF

HDF5-UDF is a mechanism to dynamically generate HDF5 datasets through
user-defined functions (UDFs) written in Lua, Python, or C/C++.

User-defined functions are compiled into executable form and the result
is embedded into HDF5. A supporting library gives access to existing datasets
from user code so that data analysis and derivation of other data can be produced.

Access to HDF5 is made through Foreign Function Interfaces (FFIs) in Python and
Lua, meaning that there is no measurable overhead when accessing input and output
datasets from such languages. UDFs written in C/C++ are compiled into shared libraries,
compressed, and embedded into HDF5 just like in the Python and Lua backends. The
difference is that, unlike a LuaJIT bytecode, for instance, shared libraries are
compiled to the target architecture, hence are not as portable.

The Lua, C/C++, and Python APIs are identical and provide the following simple
functions to interface with HDF5 datasets:

- `lib.getData("DatasetName")`: fetches DatasetName from the HDF5
   file and loads it into memory
- `lib.getDims("DatasetName")`: number of dimensions in DatasetName
   and their sizes
- `lib.getType("DatasetName")`: dataset type of DatasetName. See
   below for a list of supported dataset types
- `lib.string(member)`: get the value of a string datatype
- `lib.setString(member, value)`: write the given value to a string datatype.
   This API does boundary checks to prevent buffer overflows

The user-provided function must be named `dynamic_dataset`. That
function takes no input and produces no output; data exchange is
performed by reading from and writing to the datasets retrieved
by the API above. See the next section for examples on how to
get started with UDF scripts.

There is no difference between accessing a dataset that has been
dynamically generated and a regular one. As shown in the image
below, both are retrieved using the existing HDF5 API. Note that
differently from a regular HDF5 dataset (where the actual grid is
stored on disk), HDF5-UDF datasets require only the bytecode (or
compressed shared library) to persist on disk.

![](images/hdf5-udf.png)

# Examples

When `hdf5-udf` is executed with the user-provided Lua file as input, it
scans the code for calls to `lib.getData()` to identify dataset names.
Names that map to existing datasets in the input file will cause the
corresponding datasets to be opened in read-only mode. Names that don't
relate to existing datasets will be dynamically generated by executing
the provided Lua file (in bytecode form) each time the dataset is read.

The following are simple examples that should get you started into writing
your own functions. More examples are given in the "examples" directory of
this project.

## Declare a dynamic dataset "C" as the sum of datasets "A" and "B", in Lua
```
function dynamic_dataset()
    local a_data = lib.getData("A")
    local b_data = lib.getData("B")
    local c_data = lib.getData("C")
    local n = lib.getDims("C")[1] * lib.getDims("C")[2]
    for i=1, n do
        c_data[i] = a_data[i] + b_data[i]
    end
end
```

## Same UDF as before, but written in C++
```
extern "C" void dynamic_dataset()
{
    auto a_data = lib.getData<int>("A");
    auto b_data = lib.getData<int>("B");
    auto c_data = lib.getData<int>("C");
    auto n = lib.getDims("C")[0] * lib.getDims("C")[1];

    for (size_t i=0; i<n; ++i)
        c_data[i] = a_data[i] + b_data[i];
}
```


## Same UDF as before, but adding up the "foo" and "bar" members from Compound datasets "A" and "B", in Python
```
def dynamic_dataset():
    a_data = lib.getData("A")
    b_data = lib.getData("B")
    c_data = lib.getData("C")
    n = lib.getDims("C")[0] * lib.getDims("C")[1]

    for i in range(n):
        c_data[i] = a_data[i].foo + b_data[i].bar
```

## Declare dynamic datasets "B" and "C" as variations of dataset "A", in Lua
```
function dynamic_dataset()
    local a_data = lib.getData("A")
    local b_data = lib.getData("B")
    local c_data = lib.getData("C")
    local x = lib.getDims("A")[1]
    local y = lib.getDims("A")[2]
    for i=1, x do
        for j=1, y do
            b_data[i*y+j] = a_data[i*y+j] * 2
            c_data[i*y+j] = a_data[i*y+j] * 3
        end
    end
end
```

## Other examples

The [examples](https://github.com/lucasvr/hdf5-udf/tree/master/examples)
directory holds a collection of scripts that can be readily compiled and tested.
Please refer to their source code for build instructions and further details.

Also, make sure to read the template files for
[Lua](https://github.com/lucasvr/hdf5-udf/blob/master/src/udf_template.lua),
[Python](https://github.com/lucasvr/hdf5-udf/blob/master/src/udf_template.py), and
[C/C++](https://github.com/lucasvr/hdf5-udf/blob/master/src/udf_template.cpp)
to learn more about the APIs behind the `lib` interface.

# Configuration and execution

If the program has been installed to a directory other than `/usr/local`, then
make sure to configure the HDF5 filter search path accordingly:

```
$ export HDF5_PLUGIN_PATH=/installation/path/hdf5/lib/plugin
```

The main program takes as input a few required arguments: the HDF5 file, the
user-defined script, and the output dataset name/resolution/data type. If
we were to create a `float` dataset named "temperature" with 1000x800 cells
(and whose script is named "udf.py") then the following command would do
it (while appending the result to "myfile.h5"):

```
$ hdf5-udf myfile.h5 udf.py temperature:1000x800:float
```

It is also possible to let the main program infer the output dataset information
based on the UDF script -- as long as the script takes input from at least one
existing dataset. In that case, if the dataset name/resolution/data type is
omitted from the command line, the main program:

1. Identifies calls to `lib.getData()` in the UDF script and checks if the dataset
   name given as argument to that function exists in the HDF5 file. If it doesn't,
   then that name is used for the output dataset.
2. Identifies the resolution and data types of existing datasets taken as input.
   If all input datasets have the same resolution and data type, then the output
   dataset is produced with the same characteristics.

In such cases, invoking the program is as simple as:

```
$ hdf5-udf myfile.h5 udf.py
```

It is also possible to have more than one dataset produced by a single script.
In that case, information regarding each output variable can be provided in the
command line as extra arguments to the main program. Alternatively, their names,
resolution and data types can be guessed from the UDF script as mentioned before.

# Supported datatypes

The following dataset types can be output by `hdf5-udf`:

- `int8`, `uint8` (`H5T_STD_I8LE`, `H5T_STD_U8LE`)
- `int16`, `uint16` (`H5T_STD_I16LE`, `H5T_STD_U16LE`)
- `int32`, `uint32` (`H5T_STD_I32LE`, `H5T_STD_U32LE`)
- `int64`, `uint64` (`H5T_STD_I64LE`, `H5T_STD_U64LE`)
- `float`, `double` (`H5T_IEEE_F32LE`, `H5T_IEEE_F64LE`)
- `string` (`H5T_C_S1`)
- `compound` (`H5T_COMPOUND`)

# Support for HDF5 groups

HDF5-UDF also supports datasets stored in a non-flat hierarchy. The API accepts
dataset names that are prefixed by their group names, as in
`lib.getData("/group/name/dataset")`. It is also possible to store a UDF dataset
on a given group by using the same syntax on the command line, such as 
`/group/name/dataset:resolution:datatype`. Note that the given group must already
exist: `hdf5-udf` will not attempt to create them for you.

# Support for strings and compounds

It is possible to write UDFs that take input from compounds and from strings (both
fixed- and variable-sized ones). `hdf5-udf` will print the name and layout of the
generated structure that you can use to iterate over the input data members. Please
refer to the [examples](https://github.com/lucasvr/hdf5-udf/tree/master/examples)
directory for a guidance on how to access such datatypes from Python, C/C++ and Lua.

Also, one can write UDFs that output such datatypes. Strings have a default fixed
size of 32 characters; that value can be changed by the user using the `(N)` modifier.
For instance, to output strings with at most 8 characters one can declare a dataset
like `dataset_name:resolution:string(8)`.

The syntax for outputting compounds is slightly different, as members may have
distinct datatypes: `dataset_name:{member:type[,member:type...]}:resolution`.
A sample compound named "placemark" with a single "location" member can be entered
as `placemark:{location:string}:1000` to `hdf5-udf`.

Multiple compound members must be
separated by a comma within the curly braces delimiters. Note that it is possible
to use the `(N)` modifier with string members that belong to a compound too. In the
previous example, one could write `placemark:{location:string(48)}:1000` to limit
location strings to 48 characters.
